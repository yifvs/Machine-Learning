import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression, SGDRegressor
from sklearn.metrics import mean_squared_error
import statsmodels.api as sm
import numpy as np
import io
import matplotlib.pyplot as plt
import datetime
import seaborn as sns


# è®¾ç½®é¡µé¢å¸ƒå±€
st.set_page_config(layout="wide", page_title="Machine Learning", page_icon="ðŸ“ˆ")
# è®¾ç½®åº”ç”¨æ ‡é¢˜
st.title("æ•°æ®é¢„å¤„ç†ä¸Žæ¨¡åž‹è®­ç»ƒ Web åº”ç”¨")

# åˆ›å»ºä¸€ä¸ªè¾“å…¥æ¡†æ¥èŽ·å–headerçš„å€¼
header = st.sidebar.text_input("è¯·è¾“å…¥æ•°æ®è¡¨ä¸­åˆ—åæ‰€åœ¨çš„è¡Œå·ï¼š:violet[(æ‰‹åŠ¨è¯‘ç æ•°æ®ä¸º0ï¼Œè‡ªåŠ¨è¯‘ç æ•°æ®ä¸º4)]", "4")

# åˆ›å»ºè¾“å…¥æ¡†æ¥èŽ·å–è¦åˆ é™¤çš„è¡Œæ•°
num_rows_to_skip_before = st.sidebar.number_input("è¦è·³è¿‡çš„è¡Œæ•°ï¼ˆå‰ï¼‰ï¼š", min_value=0, value=0)
num_rows_to_skip_after = st.sidebar.number_input("è¦åˆ é™¤çš„è¡Œæ•°ï¼ˆåŽï¼‰ï¼š", min_value=0, value=0)


# ç¼“å­˜åŠ è½½æ•°æ®çš„å‡½æ•°ï¼Œæ”¯æŒå¤šä¸ªæ–‡ä»¶ä¸Šå’Œåˆå¹¶
@st.cache_data
def load_data(files, header, num_rows_to_skip_before, num_rows_to_skip_after):
    data_list = []

    for file in files:
        file_extension = file.name.split(".")[-1].lower()
        if file_extension == "csv":
            data = pd.read_csv(file, index_col=None, header=int(header), encoding='gb18030')
        elif file_extension == "xlsx":
            data = pd.read_excel(file, index_col=None, header=int(header))

        # åˆ é™¤å‰åŽæŒ‡å®šçš„è¡Œæ•°
        if num_rows_to_skip_before > 0:
            data = data.iloc[num_rows_to_skip_before:]
        if num_rows_to_skip_after > 0:
            data = data.iloc[:-num_rows_to_skip_after]

        data_list.append(data)

    # åˆå¹¶å¤šä¸ªæ–‡ä»¶
    merged_data = pd.concat(data_list, axis=0)
    return merged_data


# å¯¼å…¥æ•°æ®
uploaded_files = st.file_uploader("ðŸ“ Please select the data files to import (multiple files can be uploaded):", type=["csv", "xlsx"],
                                  accept_multiple_files=True)
data = pd.DataFrame()  # åˆå§‹åŒ–ä¸ºç©ºçš„DataFrame

if uploaded_files is not None and len(uploaded_files) > 0:
    # æ•°æ®åŠ è½½éƒ¨åˆ†
    data = load_data(uploaded_files, header, num_rows_to_skip_before, num_rows_to_skip_after)
    st.success("æ•°æ®å·²æˆåŠŸå¯¼å…¥å¹¶åˆå¹¶ï¼")

    # æ˜¾ç¤ºè¡¨æ ¼æ•°æ®
    st.subheader("åŽŸå§‹è¡¨æ ¼æ•°æ®ï¼š")
    show_data = st.checkbox('æ˜¯å¦æ˜¾ç¤ºåŽŸå§‹è¡¨æ ¼æ•°æ®çš„å‰20è¡Œ', value=False)
    if show_data:
        st.dataframe(data.head(20))

    # æ•°æ®é¢„å¤„ç†éƒ¨åˆ†
    columns = st.sidebar.multiselect("é€‰æ‹©è¦é¢„å¤„ç†çš„åˆ—", data.columns.tolist())

    if columns:
        # æ£€æŸ¥æ˜¯å¦åŒ…å«Timeåˆ—
        if 'Time' in columns:
            st.info("æ£€æµ‹åˆ°Timeåˆ—ï¼Œå°†è‡ªåŠ¨å°†å…¶è®¾ç½®ä¸ºç´¢å¼•ï¼Œå¹¶ä¿æŒå…¶æ—¶é—´æ ¼å¼")
            try:
                # é¦–å…ˆå¤„ç†Timeåˆ—ä¸­çš„ç©ºå€¼
                if data['Time'].isnull().any():
                    st.warning(f"Timeåˆ—ä¸­å­˜åœ¨ {data['Time'].isnull().sum()} ä¸ªç©ºå€¼")
                    time_na_handling = st.selectbox(
                        "è¯·é€‰æ‹©Timeåˆ—ç©ºå€¼å¤„ç†æ–¹æ³•",
                        ["åˆ é™¤ç©ºå€¼è¡Œ", "å‰å‘å¡«å……", "åŽå‘å¡«å……"]
                    )
                    
                    if time_na_handling == "åˆ é™¤ç©ºå€¼è¡Œ":
                        data = data.dropna(subset=['Time'])
                        st.info(f"å·²åˆ é™¤Timeåˆ—ä¸­çš„ç©ºå€¼è¡Œï¼Œå‰©ä½™ {len(data)} è¡Œæ•°æ®")
                    elif time_na_handling == "å‰å‘å¡«å……":
                        data['Time'].fillna(method='ffill', inplace=True)
                        st.info("å·²ç”¨å‰ä¸€ä¸ªæœ‰æ•ˆå€¼å¡«å……Timeåˆ—çš„ç©ºå€¼")
                    elif time_na_handling == "åŽå‘å¡«å……":
                        data['Time'].fillna(method='bfill', inplace=True)
                        st.info("å·²ç”¨åŽä¸€ä¸ªæœ‰æ•ˆå€¼å¡«å……Timeåˆ—çš„ç©ºå€¼")

                # æ£€æŸ¥ç¬¬ä¸€ä¸ªéžç©ºå€¼çš„ç±»åž‹å¹¶ç›¸åº”å¤„ç†
                first_valid_time = data['Time'].dropna().iloc[0]
                
                if isinstance(first_valid_time, str):
                    # å¦‚æžœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•ç›´æŽ¥è½¬æ¢
                    data['Time'] = pd.to_datetime(data['Time'], format='mixed')
                elif isinstance(first_valid_time, datetime.time):
                    # å¦‚æžœæ˜¯timeå¯¹è±¡ï¼Œå…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå†è½¬æ¢ä¸ºdatetime
                    current_date = datetime.date.today()
                    
                    def convert_time(x):
                        if pd.isna(x):
                            return None
                        try:
                            # å¦‚æžœæ˜¯timeå¯¹è±¡ï¼Œè½¬æ¢ä¸ºdatetime
                            if isinstance(x, datetime.time):
                                return datetime.datetime.combine(current_date, x)
                            # å¦‚æžœå·²ç»æ˜¯datetimeï¼Œç›´æŽ¥è¿”å›ž
                            elif isinstance(x, datetime.datetime):
                                return x
                            # å…¶ä»–æƒ…å†µè¿”å›žNone
                            return None
                        except:
                            return None
                    
                    data['Time'] = data['Time'].apply(convert_time)
                elif isinstance(first_valid_time, datetime.datetime):
                    # å¦‚æžœå·²ç»æ˜¯datetimeï¼Œä¸éœ€è¦è½¬æ¢
                    pass
                else:
                    # å…¶ä»–æƒ…å†µï¼Œå°è¯•å¼ºåˆ¶è½¬æ¢
                    data['Time'] = pd.to_datetime(data['Time'], errors='coerce')

                # è®¾ç½®ç´¢å¼•å‰å†æ¬¡æ£€æŸ¥ç©ºå€¼
                if data['Time'].isnull().any():
                    st.warning("æ—¶é—´è½¬æ¢åŽä»å­˜åœ¨ç©ºå€¼ï¼Œå°†è¢«åˆ é™¤")
                    data = data.dropna(subset=['Time'])
                
                data.set_index('Time', inplace=True)
                columns.remove('Time')
                st.success("Timeåˆ—å·²æˆåŠŸè®¾ç½®ä¸ºç´¢å¼•")
                
            except Exception as e:
                st.error(f"Timeåˆ—è½¬æ¢å¤±è´¥: {str(e)}")
                st.warning("Timeåˆ—å°†ä¿æŒåŽŸæ ¼å¼")
                columns.remove('Time')

        if columns:  # ç¡®ä¿è¿˜æœ‰å…¶ä»–åˆ—éœ€è¦å¤„ç†
            # æ•°æ®ç±»åž‹è½¬æ¢
            convert_types = st.selectbox("é€‰æ‹©æ•°æ®ç±»åž‹è½¬æ¢æ–¹å¼", ["ä¸è¿›è¡Œè½¬æ¢", "å­—ç¬¦ä¸²è½¬æ•°å€¼"])
            if convert_types == "å­—ç¬¦ä¸²è½¬æ•°å€¼":
                for col in columns:
                    data[col] = pd.to_numeric(data[col], errors='coerce')
                st.write("ç±»åž‹è½¬æ¢åŽçš„æ•°æ®é¢„è§ˆï¼š", data[columns].head(10))

            # ç©ºå€¼å¤„ç†
            missing_handling = st.selectbox("é€‰æ‹©ç©ºå€¼å¤„ç†æ–¹æ³•", ["ä¸å¤„ç†", "å‰å‘å¡«å……", "åŽå‘å¡«å……", "åˆ é™¤ç©ºå€¼", "çº¿æ€§æ’å€¼"])
            if missing_handling == "å‰å‘å¡«å……":
                data[columns] = data[columns].fillna(method='ffill')
            elif missing_handling == "åŽå‘å¡«å……":
                data[columns] = data[columns].fillna(method='bfill')
            elif missing_handling == "åˆ é™¤ç©ºå€¼":
                data = data.dropna(subset=columns)
            elif missing_handling == "çº¿æ€§æ’å€¼":
                data[columns] = data[columns].interpolate(method='linear')
            st.write("ç©ºå€¼å¤„ç†åŽçš„æ•°æ®é¢„è§ˆï¼š", data[columns].head(10))

            # å½’ä¸€åŒ–
            normalization = st.selectbox("é€‰æ‹©å½’ä¸€åŒ–æ–¹æ³•", ["ä¸è¿›è¡Œå½’ä¸€åŒ–", "æœ€å°-æœ€å¤§å½’ä¸€åŒ–", "Z-scoreæ ‡å‡†åŒ–"])
            if normalization == "æœ€å°-æœ€å¤§å½’ä¸€åŒ–":
                scaler = MinMaxScaler()
                data[columns] = scaler.fit_transform(data[columns])
            elif normalization == "Z-scoreæ ‡å‡†åŒ–":
                scaler = StandardScaler()
                data[columns] = scaler.fit_transform(data[columns])
            st.write("å½’ä¸€åŒ–åŽçš„æ•°æ®é¢„è§ˆï¼š", data[columns].head(10))

            # é¢„å¤„ç†æ•°æ®ä¸‹è½½
            st.subheader("ä¸‹è½½é¢„å¤„ç†åŽçš„æ•°æ®")
            preprocessed_data = None

            if st.button("ç”Ÿæˆé¢„å¤„ç†æ•°æ®"):
                if columns:
                    # å¦‚æžœTimeæ˜¯ç´¢å¼•ï¼Œå°†å…¶åŒ…å«åœ¨å¯¼å‡ºæ•°æ®ä¸­
                    if isinstance(data.index, pd.DatetimeIndex):
                        preprocessed_data = data[columns].copy()
                        preprocessed_data.index.name = 'Time'
                        preprocessed_data = preprocessed_data.reset_index()
                    else:
                        preprocessed_data = data[columns].copy()
                    st.success("é¢„å¤„ç†æ•°æ®å·²ç”Ÿæˆï¼Œå¯ä»¥ä¸‹è½½")
                else:
                    st.warning("è¯·å…ˆé€‰æ‹©è¦é¢„å¤„ç†çš„åˆ—")

            if preprocessed_data is not None:
                csv_buffer = io.BytesIO()
                preprocessed_data.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
                csv_buffer.seek(0)

                st.download_button(
                    label="ä¸‹è½½é¢„å¤„ç†æ•°æ®",
                    data=csv_buffer,
                    file_name="é¢„å¤„ç†æ•°æ®.csv",
                    mime="text/csv"
                )

        # ç›¸å…³æ€§åˆ†æž
        st.subheader("ç›¸å…³æ€§åˆ†æž")
        
        # é€‰æ‹©ç›®æ ‡å˜é‡
        target_var = st.selectbox(
            "é€‰æ‹©ç›®æ ‡å˜é‡",
            [""] + data.columns.tolist()
        )
        
        if target_var:
            # é€‰æ‹©ç‰¹å¾å˜é‡ï¼ˆå¤šé€‰ï¼‰
            feature_vars = st.multiselect(
                "é€‰æ‹©ç‰¹å¾å˜é‡ï¼ˆå¯å¤šé€‰ï¼‰",
                [col for col in data.columns if col != target_var]
            )
            
            if feature_vars:
                # é€‰æ‹©ç›¸å…³ç³»æ•°ç±»åž‹
                corr_method = st.radio(
                    "é€‰æ‹©ç›¸å…³ç³»æ•°ç±»åž‹",
                    ["Pearson", "Spearman"],
                    horizontal=True
                )
                
                # æ•°æ®é¢„å¤„ç†
                corr_data = data[[target_var] + feature_vars].copy()
                
                # è½¬æ¢ä¸ºæ•°å€¼ç±»åž‹
                for col in corr_data.columns:
                    corr_data[col] = pd.to_numeric(corr_data[col], errors='coerce')
                
                # ä½¿ç”¨çº¿æ€§æ’å€¼å¡«å……ç©ºå€¼
                corr_data = corr_data.interpolate(method='linear')
                # å¤„ç†é¦–å°¾çš„ç©ºå€¼
                corr_data = corr_data.fillna(method='bfill').fillna(method='ffill')
                
                if st.button("ç”Ÿæˆç›¸å…³æ€§çƒ­å›¾"):
                    # è®¡ç®—ç›¸å…³ç³»æ•°
                    corr_matrix = corr_data.corr(method=corr_method.lower())
                    
                    # åˆ›å»ºçƒ­å›¾
                    fig, ax = plt.subplots(figsize=(8, 6))
                    
                    # ä½¿ç”¨seabornç»˜åˆ¶çƒ­å›¾
                    sns.heatmap(corr_matrix, 
                               annot=True,  # æ˜¾ç¤ºç›¸å…³ç³»æ•°å€¼
                               fmt='.2f',   # ä¿ç•™ä¸¤ä½å°æ•°
                               cmap='coolwarm',  # ä½¿ç”¨çº¢è“è‰²å›¾
                               center=0,    # å°†0è®¾ä¸ºä¸­å¿ƒå€¼
                               square=True, # ä¿æŒæ–¹å½¢
                               ax=ax)
                    
                    plt.title(f'{corr_method} Correlation Matrix')
                    
                    # è°ƒæ•´å¸ƒå±€
                    plt.tight_layout()
                    
                    # æ˜¾ç¤ºå›¾å½¢
                    st.pyplot(fig)
                    plt.close()
                    
                    # æ˜¾ç¤ºä¸Žç›®æ ‡å˜é‡çš„ç›¸å…³æ€§æŽ’åº
                    st.write(f"ä¸Ž{target_var}çš„{corr_method}ç›¸å…³ç³»æ•°æŽ’åºï¼š")
                    
                    # èŽ·å–ç›®æ ‡å˜é‡çš„ç›¸å…³ç³»æ•°å¹¶æŽ’åº
                    target_corr = corr_matrix[target_var].drop(target_var)
                    target_corr_sorted = target_corr.abs().sort_values(ascending=False)
                    
                    # åˆ›å»ºä¸€ä¸ªDataFrameæ¥æ˜¾ç¤ºç›¸å…³æ€§æŽ’åº
                    corr_df = pd.DataFrame({
                        'å˜é‡': target_corr_sorted.index,
                        'ç›¸å…³ç³»æ•°': target_corr[target_corr_sorted.index],
                        'ç»å¯¹å€¼': target_corr_sorted.values
                    })
                    
                    # è®¾ç½®æ˜¾ç¤ºæ ¼å¼
                    pd.set_option('display.float_format', lambda x: '%.3f' % x)
                    
                    # æ˜¾ç¤ºç»“æžœ
                    st.write(corr_df)
                    
                    # æ·»åŠ è§£é‡Šæ€§æ–‡æœ¬
                    st.info("""
                    ç›¸å…³ç³»æ•°è§£é‡Šï¼š
                    - å–å€¼èŒƒå›´ï¼š-1 åˆ° 1
                    - 1ï¼šå®Œå…¨æ­£ç›¸å…³
                    - -1ï¼šå®Œå…¨è´Ÿç›¸å…³
                    - 0ï¼šæ— ç›¸å…³æ€§
                    - ç»å¯¹å€¼è¶Šå¤§è¡¨ç¤ºç›¸å…³æ€§è¶Šå¼º
                    """)

        # é¢‘è°±åˆ†æžéƒ¨åˆ†
        st.subheader("é¢‘è°±åˆ†æž")
        spectrum_columns = st.multiselect("é€‰æ‹©è¦è¿›è¡Œé¢‘è°±åˆ†æžçš„åˆ—", data.columns.tolist(), key='spectrum_cols')
        
        if spectrum_columns:
            analysis_type = st.selectbox("é€‰æ‹©åˆ†æžæ–¹æ³•", ["å¿«é€Ÿå‚…é‡Œå¶å˜æ¢(FFT)", "è¿žç»­å°æ³¢å˜æ¢(CWT)"])
            
            if analysis_type == "å¿«é€Ÿå‚…é‡Œå¶å˜æ¢(FFT)":
                if st.button("ç”ŸæˆFFTé¢‘è°±å›¾"):
                    # Calculate layout
                    n_cols = min(2, len(spectrum_columns))
                    n_rows = (len(spectrum_columns) + n_cols - 1) // n_cols
                    
                    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 3*n_rows))
                    if len(spectrum_columns) == 1:
                        axes = np.array([[axes]])
                    elif n_rows == 1:
                        axes = axes.reshape(1, -1)
                    
                    for idx, col in enumerate(spectrum_columns):
                        row = idx // n_cols
                        col_idx = idx % n_cols
                        
                        signal = data[col].values
                        n = len(signal)
                        fft_result = np.fft.fft(signal)
                        freq = np.fft.fftfreq(n, d=1)
                        
                        axes[row, col_idx].plot(freq[:n//2], np.abs(fft_result)[:n//2])
                        axes[row, col_idx].set_title(f'FFT of {col}')
                        axes[row, col_idx].set_xlabel('Frequency (Hz)')
                        axes[row, col_idx].set_ylabel('Magnitude')
                        axes[row, col_idx].grid(True)
                    
                    # Handle extra subplots
                    for idx in range(len(spectrum_columns), n_rows * n_cols):
                        row = idx // n_cols
                        col_idx = idx % n_cols
                        fig.delaxes(axes[row, col_idx])
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.close()
            
            else:  # CWTåˆ†æž
                if st.button("ç”ŸæˆCWTæ—¶é¢‘å›¾"):
                    import pywt
                    scales = np.arange(1, 128)
                    wavelet = 'morl'
                    
                    for col in spectrum_columns:
                        signal = data[col].values
                        coefficients, frequencies = pywt.cwt(signal, scales, wavelet)
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # 2D Time-Frequency plot
                            fig, ax = plt.subplots(figsize=(5, 3))
                            im = ax.pcolormesh(np.arange(len(signal)), frequencies, np.abs(coefficients))
                            ax.set_title(f'CWT of {col}')
                            ax.set_ylabel('Frequency (Hz)')
                            ax.set_xlabel('Time (s)')
                            cbar = plt.colorbar(im, ax=ax, label='Magnitude')
                            # è°ƒæ•´colorbarçš„å­—ä½“å¤§å°
                            cbar.ax.tick_params(labelsize=8)
                            # è°ƒæ•´ä¸»å›¾çš„å­—ä½“å¤§å°
                            ax.tick_params(labelsize=8)
                            plt.tight_layout()
                            st.pyplot(fig)
                            plt.close()
                        
                        with col2:
                            # 3D Time-Frequency plot
                            fig = plt.figure(figsize=(5, 3))
                            ax = fig.add_subplot(111, projection='3d')
                            time_grid, scale_grid = np.meshgrid(np.arange(len(signal)), frequencies)
                            surf = ax.plot_surface(time_grid, scale_grid, np.abs(coefficients), 
                                                cmap='viridis')
                            ax.set_title(f'3D CWT of {col}', pad=2)  # å‡å°æ ‡é¢˜å’Œå›¾ä¹‹é—´çš„é—´è·
                            ax.set_xlabel('Time (s)', labelpad=2)    # å‡å°æ ‡ç­¾å’Œè½´ä¹‹é—´çš„é—´è·
                            ax.set_ylabel('Frequency (Hz)', labelpad=2)
                            ax.set_zlabel('Magnitude', labelpad=2)
                            # è°ƒæ•´è§†è§’
                            ax.view_init(elev=30, azim=45)
                            # è°ƒæ•´è½´æ ‡ç­¾å­—ä½“å¤§å°
                            ax.tick_params(labelsize=8)
                            cbar = plt.colorbar(surf, ax=ax, label='Magnitude', pad=0.1)  # å‡å°colorbarçš„é—´è·
                            cbar.ax.tick_params(labelsize=8)
                            plt.tight_layout()
                            st.pyplot(fig)
                            plt.close()

        # æ¦‚çŽ‡å¯†åº¦åˆ†å¸ƒåˆ†æžéƒ¨åˆ†
        st.subheader("æ¦‚çŽ‡å¯†åº¦åˆ†å¸ƒåˆ†æž")
        
        # å¤šé€‰
        density_columns = st.multiselect(
            "é€‰æ‹©è¦åˆ†æžæ¦‚çŽ‡å¯†åº¦åˆ†å¸ƒçš„åˆ—ï¼ˆå¯å¤šé€‰ï¼‰",
            data.columns.tolist()
        )
        
        if density_columns:
            # é€‰æ‹©ç­›é€‰æ¡ä»¶çš„åˆ—ï¼ˆå¯å¤šé€‰ï¼‰
            filter_columns = st.multiselect(
                "é€‰æ‹©ç”¨äºŽç­›é€‰æ•°æ®èŒƒå›´çš„åˆ—ï¼ˆå¯å¤šé€‰ï¼‰",
                [col for col in data.columns if col not in density_columns]  # æŽ’é™¤å·²é€‰æ‹©çš„åˆ†æžåˆ—
            )
            
            if filter_columns:
                # æ•°æ®é¢„å¤„ç†
                processed_data = data.copy()
                
                for col in filter_columns:
                    processed_data[col] = pd.to_numeric(processed_data[col], errors='coerce')
                    processed_data[col] = processed_data[col].interpolate(method='linear')
                    processed_data[col] = processed_data[col].fillna(method='bfill').fillna(method='ffill')
                
                st.info(f"æ•°æ®é¢„å¤„ç†å®Œæˆï¼š\n" + 
                       "\n".join([f"{col}: {processed_data[col].isna().sum()} ä¸ªç©ºå€¼" 
                                 for col in filter_columns]))
                
                filter_conditions = []
                filter_ranges = {}
                
                st.write("è®¾ç½®æ•°æ®ç­›é€‰èŒƒå›´ï¼š")
                for col in filter_columns:
                    min_val = float(processed_data[col].min())
                    max_val = float(processed_data[col].max())
                    
                    range_min, range_max = st.slider(
                        f"é€‰æ‹© {col} çš„èŒƒå›´",
                        min_value=min_val,
                        max_value=max_val,
                        value=(min_val, max_val),
                        step=(max_val - min_val) / 100
                    )
                    
                    filter_ranges[col] = (range_min, range_max)
                    filter_conditions.append(
                        (processed_data[col] >= range_min) & (processed_data[col] <= range_max)
                    )
            
            if st.button("ç”Ÿæˆæ¦‚çŽ‡å¯†åº¦åˆ†å¸ƒå›¾"):
                # åº”ç”¨ç­›é€‰æ¡ä»¶
                if filter_columns and filter_conditions:
                    final_filter = filter_conditions[0]
                    for condition in filter_conditions[1:]:
                        final_filter = final_filter & condition
                    filtered_data = processed_data[final_filter][density_columns]
                else:
                    filtered_data = data[density_columns]
                
                # ä¸ºæ¯ä¸ªé€‰æ‹©çš„åˆ—åˆ›å»ºæ¦‚çŽ‡å¯†åº¦åˆ†å¸ƒå›¾
                fig, ax = plt.subplots(figsize=(12, 6))
                
                # ä½¿ç”¨ä¸åŒé¢œè‰²ç»˜åˆ¶æ¯ä¸ªåˆ—çš„åˆ†å¸ƒ
                for col in density_columns:
                    # æ ¸å¯†åº¦ä¼°è®¡
                    filtered_data[col].plot.kde(ax=ax, linewidth=2, label=f'{col} (KDE)')
                    # ç›´æ–¹å›¾
                    filtered_data[col].hist(ax=ax, density=True, alpha=0.1, bins=30, 
                                         label=f'{col} (Hist)')
                
                # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
                ax.set_title('Probability Density Distribution')
                ax.set_xlabel('Value')
                ax.set_ylabel('Density')
                
                # æ·»åŠ ç½‘æ ¼
                ax.grid(True, alpha=0.3)
                
                # æ·»åŠ å›¾ä¾‹ï¼ˆä¸Šæ–¹ï¼‰
                ax.legend(loc='upper right', bbox_to_anchor=(1.0, 1.0))
                
                # ä½¿ç”¨è½´åæ ‡æ·»åŠ ç­›é€‰æ¡ä»¶æ–‡æœ¬ï¼ˆå·¦ä¸‹è§’ï¼‰
                if filter_conditions:
                    filter_text = "ç­›é€‰æ¡ä»¶:\n"
                    for col in filter_columns:
                        range_min, range_max = filter_ranges[col]
                        filter_text += f"{col}: [{range_min:.2f}, {range_max:.2f}]\n"
                    
                    x_min, x_max = ax.get_xlim()
                    y_min, y_max = ax.get_ylim()
                    text_x = x_min + (x_max - x_min) * 0.02
                    text_y = y_min + (y_max - y_min) * 0.02
                    
                    ax.text(text_x, text_y, filter_text,
                           fontsize=8,
                           va='bottom',
                           ha='left',
                           bbox=dict(facecolor='white',
                                   alpha=0.8,
                                   edgecolor='none',
                                   pad=1.5))
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ˆå³ä¸‹è§’ï¼‰
                stats_text = "ç»Ÿè®¡ä¿¡æ¯:\n"
                for col in density_columns:
                    stats = filtered_data[col]
                    stats_text += f"\n{col}:\n"
                    stats_text += f"æ•°æ®é‡: {len(stats)}\n"
                    stats_text += f"å‡å€¼: {stats.mean():.2f}\n"
                    stats_text += f"æ ‡å‡†å·®: {stats.std():.2f}\n"
                    stats_text += f"æœ€å°å€¼: {stats.min():.2f}\n"
                    stats_text += f"æœ€å¤§å€¼: {stats.max():.2f}\n"
                
                # èŽ·å–è½´çš„èŒƒå›´
                x_min, x_max = ax.get_xlim()
                y_min, y_max = ax.get_ylim()
                
                # åœ¨å³ä¸‹è§’æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                ax.text(x_max - (x_max - x_min) * 0.02,  # è·ç¦»å³è¾¹ç•Œ2%
                       y_min + (y_max - y_min) * 0.02,   # è·ç¦»ä¸‹è¾¹ç•Œ2%
                       stats_text,
                       fontsize=10,
                       va='bottom',
                       ha='right',  # å³å¯¹é½
                       bbox=dict(facecolor='white',
                               alpha=0.8,
                               edgecolor='none',
                               pad=1.5))
                
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()
                
                # æ˜¾ç¤ºæè¿°æ€§ç»Ÿè®¡ä¿¡æ¯
                st.write("æè¿°æ€§ç»Ÿè®¡ï¼š")
                desc_stats = filtered_data.describe()
                
                # é‡å‘½åç´¢å¼•ä¸ºä¸­æ–‡
                stats_names = {
                    'count': 'æ•°é‡',
                    'mean': 'å‡å€¼',
                    'std': 'æ ‡å‡†å·®',
                    'min': 'æœ€å°å€¼',
                    '25%': '25%åˆ†ä½æ•°',
                    '50%': 'ä¸­ä½æ•°',
                    '75%': '75%åˆ†ä½æ•°',
                    'max': 'æœ€å¤§å€¼'
                }
                desc_stats.index = [stats_names.get(i, i) for i in desc_stats.index]
                
                st.write(desc_stats)

        # æ¨¡åž‹è®­ç»ƒéƒ¨åˆ†
        st.subheader("æ¨¡åž‹è®­ç»ƒ")
        
        # æ·»åŠ ç©ºé€‰é¡¹ä½œä¸ºé»˜è®¤å€¼
        target_options = [""] + data.columns.tolist()
        target_column = st.selectbox("é€‰æ‹©ç›®æ ‡åˆ—ï¼ˆé¢„æµ‹ç›®æ ‡ï¼‰ï¼š", target_options)
        
        # åªæœ‰å½“é€‰æ‹©äº†ç›®æ ‡åˆ—æ—¶æ‰æ˜¾ç¤ºåŽç»­é€‰é¡¹
        if target_column:
            feature_columns = st.multiselect("é€‰æ‹©ç‰¹å¾åˆ—ï¼š", [col for col in data.columns if col != target_column])

            model_choice = st.selectbox("é€‰æ‹©æ¨¡åž‹", ["çº¿æ€§å›žå½’", "å¤šé¡¹å¼å›žå½’", "ARIMA", "æ¢¯åº¦ä¸‹é™"])

            if model_choice == "å¤šé¡¹å¼å›žå½’":
                degree = st.number_input("å¤šé¡¹å¼å›žå½’çš„é˜¶æ•°", min_value=2, max_value=5, value=2)

            elif model_choice == "ARIMA":
                p = st.number_input("ARIMAçš„på‚æ•°", min_value=0, max_value=5, value=1)
                d = st.number_input("ARIMAçš„då‚æ•°", min_value=0, max_value=5, value=1)
                q = st.number_input("ARIMAçš„qå‚æ•°", min_value=0, max_value=5, value=1)

            elif model_choice == "æ¢¯åº¦ä¸‹é™":
                learning_rate = st.slider("é€‰æ‹©å­¦ä¹ çŽ‡", min_value=0.0001, max_value=1.0, value=0.01)
                max_iter = st.number_input("æœ€å¤§è¿­ä»£æ¬¡æ•°", min_value=100, max_value=10000, value=1000)
                tol = st.number_input("å®¹å¿åº¦", min_value=1e-3, max_value=1.0, value=1e-2)
                random_state = st.number_input("éšæœºç§å­", min_value=0, max_value=1000, value=42)

            if st.button("å¼€å§‹è®­ç»ƒæ¨¡åž‹"):
                X = data[feature_columns]
                y = data[target_column]

                # ä¿æŒç´¢å¼•çš„åˆ‡åˆ†
                train_size = int(len(data) * 0.8)
                train_index = data.index[:train_size]
                test_index = data.index[train_size:]
                
                # æŒ‰ç´¢å¼•åˆ‡åˆ†æ•°æ®
                X_train = X.loc[train_index]
                X_test = X.loc[test_index]
                y_train = y.loc[train_index]
                y_test = y.loc[test_index]

                if model_choice == "çº¿æ€§å›žå½’":
                    model = LinearRegression()
                    model.fit(X_train, y_train)
                    y_train_pred = model.predict(X_train)
                    y_test_pred = model.predict(X_test)
                    mse = mean_squared_error(y_test, y_test_pred)
                    st.write(f"çº¿æ€§å›žå½’å‡æ–¹è¯¯å·®: {mse}")

                elif model_choice == "å¤šé¡¹å¼å›žå½’":
                    poly = PolynomialFeatures(degree=degree)
                    X_poly_train = poly.fit_transform(X_train)
                    X_poly_test = poly.transform(X_test)
                    model = LinearRegression()
                    model.fit(X_poly_train, y_train)
                    y_train_pred = model.predict(X_poly_train)
                    y_test_pred = model.predict(X_poly_test)
                    mse = mean_squared_error(y_test, y_test_pred)
                    st.write(f"å¤šé¡¹å¼å›žå½’ï¼ˆ{degree}é˜¶ï¼‰å‡æ–¹è¯¯å·®: {mse}")

                elif model_choice == "ARIMA":
                    model = sm.tsa.ARIMA(y_train, order=(p, d, q))
                    model_fit = model.fit()
                    y_train_pred = model_fit.predict(start=y_train.index[0], end=y_train.index[-1])
                    y_test_pred = model_fit.forecast(steps=len(y_test))
                    mse = mean_squared_error(y_test, y_test_pred)
                    st.write(f"ARIMA æ¨¡åž‹å‡æ–¹è¯¯å·®: {mse}")

                elif model_choice == "æ¢¯åº¦ä¸‹é™":
                    model = SGDRegressor(learning_rate='constant', eta0=learning_rate, 
                                       max_iter=max_iter, tol=tol, random_state=random_state)
                    model.fit(X_train, y_train)
                    y_train_pred = model.predict(X_train)
                    y_test_pred = model.predict(X_test)
                    mse = mean_squared_error(y_test, y_test_pred)
                    st.write(f"æ¢¯åº¦ä¸‹é™æ¨¡åž‹å‡æ–¹è¯¯å·®: {mse}")

                # ç»˜åˆ¶é¢„æµ‹å€¼ä¸Žå®žé™…å€¼å¯¹æ¯”å›¾
                st.subheader("é¢„æµ‹ç»“æžœä¸Žå®žé™…å€¼å¯¹æ¯”")
                
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
                
                # Training set
                ax1.plot(train_index, y_train.values, label='Actual', linewidth=1)
                ax1.plot(train_index, y_train_pred, '--', label='Predicted', linewidth=1)
                ax1.set_title('Training Data')
                ax1.set_xlabel('Time')
                ax1.set_ylabel('Value')
                ax1.legend()
                ax1.grid(True)
                plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
                
                # Test set
                ax2.plot(test_index, y_test.values, label='Actual', linewidth=1)
                ax2.plot(test_index, y_test_pred, '--', label='Predicted', linewidth=1)
                ax2.set_title('Test Data')
                ax2.set_xlabel('Time')
                ax2.set_ylabel('Value')
                ax2.legend()
                ax2.grid(True)
                plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
                
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

# æ·»åŠ ä¾§è¾¹æ ä¿¡æ¯
        
# æ·»åŠ åˆ†éš”çº¿
st.sidebar.markdown("---")
        
# æ·»åŠ å¼€å‘è€…ä¿¡æ¯
st.sidebar.markdown("""
### å¼€å‘è€…ä¿¡æ¯
        
**å¼€å‘è€…**ï¼šçŽ‹åº·ä¸š  
**é‚®ç®±**ï¼škangy_wang@hnair.com
        
---
        
### ç‰ˆæƒå£°æ˜Ž
                                     
æœ¬åº”ç”¨ç¨‹åºå—è‘—ä½œæƒæ³•å’Œå…¶ä»–çŸ¥è¯†äº§æƒæ³•ä¿æŠ¤ã€‚  
æœªç»æŽˆæƒï¼Œç¦æ­¢å¤åˆ¶ã€ä¿®æ”¹æˆ–åˆ†å‘æœ¬ç¨‹åºçš„ä»»ä½•éƒ¨åˆ†ã€‚
                    
Version 1.0.0
""")
        
# æ·»åŠ ä¸€äº›ç©ºè¡Œæ¥ç¡®ä¿ç‰ˆæƒä¿¡æ¯åœ¨åº•éƒ¨
st.sidebar.markdown("<br>" * 5, unsafe_allow_html=True)
